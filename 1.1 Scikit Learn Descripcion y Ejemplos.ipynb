{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> SCIKIT LEARN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn, también conocido como sklearn, es una biblioteca de machine learning de código abierto para el lenguaje de programación Python. Es una de las bibliotecas más populares y ampliamente utilizadas en la comunidad de machine learning debido a su simplicidad y su enfoque en la facilidad de uso.\n",
    "\n",
    "scikit-learn proporciona una amplia gama de algoritmos y herramientas para tareas de machine learning, incluyendo clasificación, regresión, clustering, reducción de dimensionalidad, selección de características y más. Además, también ofrece utilidades para preprocesar datos, evaluar modelos, realizar validación cruzada y ajustar hiperparámetros.\n",
    "\n",
    "La biblioteca se basa en otras bibliotecas de Python como NumPy, SciPy y matplotlib, lo que le permite aprovechar sus capacidades para cálculos numéricos, operaciones matemáticas y visualización de datos.\n",
    "\n",
    "Características clave de scikit-learn:\n",
    "\n",
    "1. Interfaz unificada: scikit-learn tiene una interfaz unificada y coherente para la mayoría de los algoritmos de machine learning, lo que facilita el cambio entre diferentes algoritmos y su comparación.\n",
    "\n",
    "2. Documentación detallada: scikit-learn proporciona una documentación exhaustiva con ejemplos prácticos, lo que facilita el aprendizaje y la implementación de los algoritmos.\n",
    "\n",
    "3. Amplia selección de algoritmos: La biblioteca ofrece una amplia variedad de algoritmos de machine learning, desde métodos tradicionales hasta técnicas más avanzadas.\n",
    "\n",
    "4. Enfoque en la calidad del software: scikit-learn se centra en la calidad del software y sigue buenas prácticas de desarrollo, lo que garantiza la robustez y eficiencia de los algoritmos implementados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulos\n",
    "scikit-learn cuenta con una amplia variedad de módulos que cubren diferentes aspectos del machine learning y tareas relacionadas. A continuación, se enumeran algunos de los módulos más importantes de scikit-learn:\n",
    "\n",
    "1. sklearn.datasets: Proporciona funciones para cargar conjuntos de datos de ejemplo, como iris, diabetes, boston, etc.\n",
    "\n",
    "2. sklearn.preprocessing: Contiene herramientas para preprocesar los datos antes de utilizarlos en modelos de machine learning, como escalamiento, normalización, codificación de variables categóricas, etc.\n",
    "\n",
    "3. sklearn.model_selection: Ofrece funciones para dividir los datos en conjuntos de entrenamiento y prueba, realizar validación cruzada, buscar hiperparámetros óptimos y evaluar modelos.\n",
    "\n",
    "4. sklearn.feature_selection: Proporciona métodos para la selección automática de características relevantes para el modelo.\n",
    "\n",
    "5. sklearn.feature_extraction: Contiene herramientas para extraer características a partir de datos brutos, como texto o imágenes.\n",
    "\n",
    "6. sklearn.linear_model: Ofrece implementaciones de modelos de regresión lineal, como la regresión lineal ordinaria, la regresión logística, la regresión Ridge, etc.\n",
    "\n",
    "7. sklearn.tree: Contiene implementaciones de árboles de decisión, como el árbol de decisión clásico, el bosque aleatorio y el aumento de gradiente.\n",
    "\n",
    "8. sklearn.ensemble: Proporciona algoritmos de ensemble, como bosques aleatorios, aumento de gradiente y votación.\n",
    "\n",
    "9. sklearn.cluster: Ofrece algoritmos de clustering, como k-means, DBSCAN y clustering espectral.\n",
    "\n",
    "10. sklearn.metrics: Contiene métricas de evaluación de modelos, como precisión, recall, puntuación F1, matriz de confusión, etc.\n",
    "\n",
    "11. sklearn.neural_network: Proporciona algoritmos de redes neuronales, como MLP (perceptrón multicapa) y algoritmos de aprendizaje profundo.\n",
    "\n",
    "12. sklearn.svm: Ofrece implementaciones de máquinas de vectores de soporte (SVM) para clasificación y regresión.\n",
    "\n",
    "Estos son solo algunos de los módulos más utilizados en scikit-learn, pero la biblioteca cuenta con muchos más. Puedes consultar la documentación oficial de scikit-learn para obtener información detallada sobre todos los módulos y sus funcionalidades.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. El Dataset de iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 8.3/8.3 MB 40.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.1.2\n",
      "    Uninstalling scikit-learn-1.1.2:\n",
      "      Successfully uninstalled scikit-learn-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado: 'C:\\\\Users\\\\tesbh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~klearn\\\\.libs\\\\vcomp140.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Importando la libreria\n",
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Imprimir las características del conjunto de datos\n",
    "print(iris.feature_names)\n",
    "\n",
    "# Imprimir las etiquetas de las clases\n",
    "print(iris.target_names)\n",
    "\n",
    "# Imprimir la forma de los datos\n",
    "print(iris.data.shape)\n",
    "\n",
    "# Imprimir las primeras 5 filas de los datos\n",
    "print(iris.data[:5])\n",
    "\n",
    "# Imprimir las etiquetas correspondientes a las primeras 5 filas\n",
    "print(iris.target[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos Iris es un conjunto de datos muy conocido y ampliamente utilizado en el campo del machine learning. Contiene información sobre diferentes especies de flores Iris, y el objetivo es predecir la especie en función de las medidas de longitud y ancho del sépalo y del pétalo.\n",
    "\n",
    "En el ejemplo anterior, se cargan los datos utilizando la función load_iris. Luego, se imprimen las características del conjunto de datos, las etiquetas de las clases, la forma de los datos (150 filas y 4 columnas) y las primeras 5 filas de los datos y sus etiquetas correspondientes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. El módulo sklearn.preprocessing de scikit-learn \n",
    "\n",
    "Proporciona herramientas para preprocesar los datos antes de utilizarlos en modelos de machine learning. Estas herramientas ayudan a transformar y normalizar los datos, manejar valores faltantes, codificar variables categóricas y más. A continuación, se presentan algunas de las principales funcionalidades del módulo sklearn.preprocessing:\n",
    "\n",
    "1. Escalamiento de características:\n",
    "\n",
    "* StandardScaler: Escala las características para que tengan media cero y desviación estándar uno.\n",
    "\n",
    "* MinMaxScaler: Escala las características para que estén dentro de un rango específico, generalmente entre 0 y 1.\n",
    "\n",
    "*  RobustScaler: Escala las características utilizando estadísticas robustas a los valores atípicos.\n",
    "\n",
    "2. Normalización:\n",
    "\n",
    "* Normalizer: Normaliza cada muestra para que su norma sea unitaria.\n",
    "\n",
    "3. Codificación de variables categóricas:\n",
    "\n",
    "* OneHotEncoder: Codifica variables categóricas en un formato de \"one-hot encoding\".\n",
    "\n",
    "* LabelEncoder: Codifica variables categóricas en valores numéricos.\n",
    "\n",
    "4. Manejo de valores faltantes:\n",
    "\n",
    "* SimpleImputer: Rellena los valores faltantes utilizando una estrategia específica, como la media, la mediana o el valor más frecuente.\n",
    "\n",
    "5. Transformaciones no lineales:\n",
    "\n",
    "* PolynomialFeatures: Genera nuevas características polinomiales a partir de las características existentes.\n",
    "\n",
    "6. Discretización:\n",
    "\n",
    "* KBinsDiscretizer: Discretiza características continuas en intervalos discretos.\n",
    "\n",
    "Estas son solo algunas de las funcionalidades principales que ofrece el módulo sklearn.preprocessing. Puedes consultar la documentación oficial de scikit-learn para obtener información más detallada sobre cada función y cómo utilizarlas en tus pipelines de preprocesamiento de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "[[ 1.76405235  0.40015721  0.97873798]\n",
      " [ 2.2408932   1.86755799 -0.97727788]\n",
      " [ 0.95008842 -0.15135721 -0.10321885]\n",
      " [ 0.4105985   0.14404357  1.45427351]\n",
      " [ 0.76103773  0.12167502  0.44386323]\n",
      " [ 0.33367433  1.49407907 -0.20515826]\n",
      " [ 0.3130677  -0.85409574 -2.55298982]\n",
      " [ 0.6536186   0.8644362  -0.74216502]\n",
      " [ 2.26975462 -1.45436567  0.04575852]\n",
      " [-0.18718385  1.53277921  1.46935877]\n",
      " [ 0.15494743  0.37816252 -0.88778575]\n",
      " [-1.98079647 -0.34791215  0.15634897]\n",
      " [ 1.23029068  1.20237985 -0.38732682]\n",
      " [-0.30230275 -1.04855297 -1.42001794]\n",
      " [-1.70627019  1.9507754  -0.50965218]\n",
      " [-0.4380743  -1.25279536  0.77749036]\n",
      " [-1.61389785 -0.21274028 -0.89546656]\n",
      " [ 0.3869025  -0.51080514 -1.18063218]\n",
      " [-0.02818223  0.42833187  0.06651722]\n",
      " [ 0.3024719  -0.63432209 -0.36274117]\n",
      " [-0.67246045 -0.35955316 -0.81314628]\n",
      " [-1.7262826   0.17742614 -0.40178094]\n",
      " [-1.63019835  0.46278226 -0.90729836]\n",
      " [ 0.0519454   0.72909056  0.12898291]\n",
      " [ 1.13940068 -1.23482582  0.40234164]\n",
      " [-0.68481009 -0.87079715 -0.57884966]\n",
      " [-0.31155253  0.05616534 -1.16514984]\n",
      " [ 0.90082649  0.46566244 -1.53624369]\n",
      " [ 1.48825219  1.89588918  1.17877957]\n",
      " [-0.17992484 -1.07075262  1.05445173]\n",
      " [-0.40317695  1.22244507  0.20827498]\n",
      " [ 0.97663904  0.3563664   0.70657317]\n",
      " [ 0.01050002  1.78587049  0.12691209]\n",
      " [ 0.40198936  1.8831507  -1.34775906]\n",
      " [-1.270485    0.96939671 -1.17312341]\n",
      " [ 1.94362119 -0.41361898 -0.74745481]\n",
      " [ 1.92294203  1.48051479  1.86755896]\n",
      " [ 0.90604466 -0.86122569  1.91006495]\n",
      " [-0.26800337  0.8024564   0.94725197]\n",
      " [-0.15501009  0.61407937  0.92220667]\n",
      " [ 0.37642553 -1.09940079  0.29823817]\n",
      " [ 1.3263859  -0.69456786 -0.14963454]\n",
      " [-0.43515355  1.84926373  0.67229476]\n",
      " [ 0.40746184 -0.76991607  0.53924919]\n",
      " [-0.67433266  0.03183056 -0.63584608]\n",
      " [ 0.67643329  0.57659082 -0.20829876]\n",
      " [ 0.39600671 -1.09306151 -1.49125759]\n",
      " [ 0.4393917   0.1666735   0.63503144]\n",
      " [ 2.38314477  0.94447949 -0.91282223]\n",
      " [ 1.11701629 -1.31590741 -0.4615846 ]\n",
      " [-0.06824161  1.71334272 -0.74475482]\n",
      " [-0.82643854 -0.09845252 -0.66347829]\n",
      " [ 1.12663592 -1.07993151 -1.14746865]\n",
      " [-0.43782004 -0.49803245  1.92953205]\n",
      " [ 0.94942081  0.08755124 -1.22543552]\n",
      " [ 0.84436298 -1.00021535 -1.5447711 ]\n",
      " [ 1.18802979  0.31694261  0.92085882]\n",
      " [ 0.31872765  0.85683061 -0.65102559]\n",
      " [-1.03424284  0.68159452 -0.80340966]\n",
      " [-0.68954978 -0.4555325   0.01747916]\n",
      " [-0.35399391 -1.37495129 -0.6436184 ]\n",
      " [-2.22340315  0.62523145 -1.60205766]\n",
      " [-1.10438334  0.05216508 -0.739563  ]\n",
      " [ 1.5430146  -1.29285691  0.26705087]\n",
      " [-0.03928282 -1.1680935   0.52327666]\n",
      " [-0.17154633  0.77179055  0.82350415]\n",
      " [ 2.16323595  1.33652795 -0.36918184]\n",
      " [-0.23937918  1.0996596   0.65526373]\n",
      " [ 0.64013153 -1.61695604 -0.02432612]\n",
      " [-0.73803091  0.2799246  -0.09815039]\n",
      " [ 0.91017891  0.31721822  0.78632796]\n",
      " [-0.4664191  -0.94444626 -0.41004969]\n",
      " [-0.01702041  0.37915174  2.25930895]\n",
      " [-0.04225715 -0.955945   -0.34598178]\n",
      " [-0.46359597  0.48148147 -1.54079701]\n",
      " [ 0.06326199  0.15650654  0.23218104]\n",
      " [-0.59731607 -0.23792173 -1.42406091]\n",
      " [-0.49331988 -0.54286148  0.41605005]\n",
      " [-1.15618243  0.7811981   1.49448454]\n",
      " [-2.06998503  0.42625873  0.67690804]\n",
      " [-0.63743703 -0.39727181 -0.13288058]\n",
      " [-0.29779088 -0.30901297 -1.67600381]\n",
      " [ 1.15233156  1.07961859 -0.81336426]\n",
      " [-1.46642433  0.52106488 -0.57578797]\n",
      " [ 0.14195316 -0.31932842  0.69153875]\n",
      " [ 0.69474914 -0.72559738 -1.38336396]\n",
      " [-1.5829384   0.61037938 -1.18885926]\n",
      " [-0.50681635 -0.59631404 -0.0525673 ]\n",
      " [-1.93627981  0.1887786   0.52389102]\n",
      " [ 0.08842209 -0.31088617  0.09740017]\n",
      " [ 0.39904635 -2.77259276  1.95591231]\n",
      " [ 0.39009332 -0.65240858 -0.39095338]\n",
      " [ 0.49374178 -0.11610394 -2.03068447]\n",
      " [ 2.06449286 -0.11054066  1.02017271]\n",
      " [-0.69204985  1.53637705  0.28634369]\n",
      " [ 0.60884383 -1.04525337  1.21114529]\n",
      " [ 0.68981816  1.30184623 -0.62808756]\n",
      " [-0.48102712  2.3039167  -1.06001582]\n",
      " [-0.1359497   1.13689136  0.09772497]\n",
      " [ 0.58295368 -0.39944903  0.37005589]]\n",
      "\n",
      "Datos escalados:\n",
      "[[ 1.62132212  0.29928405  1.13006146]\n",
      " [ 2.08606382  1.79354171 -0.87408569]\n",
      " [ 0.82801135 -0.26232438  0.02148113]\n",
      " [ 0.30221021  0.03848293  1.61729839]\n",
      " [ 0.64375754  0.01570498  0.58202515]\n",
      " [ 0.22723788  1.41322725 -0.08296668]\n",
      " [ 0.20715411 -0.97792467 -2.48857085]\n",
      " [ 0.53906402  0.77206043 -0.63318746]\n",
      " [ 2.11419293 -1.58918096  0.17412436]\n",
      " [-0.28040428  1.4526357   1.63275485]\n",
      " [ 0.05304591  0.27688681 -0.78239144]\n",
      " [-2.02850656 -0.46247674  0.28743608]\n",
      " [ 1.10110388  1.11618925 -0.26961782]\n",
      " [-0.3926022  -1.17594092 -1.32772016]\n",
      " [-1.76094599  1.87828219 -0.39495322]\n",
      " [-0.52492875 -1.38392144  0.92386177]\n",
      " [-1.67091747 -0.3248309  -0.79026126]\n",
      " [ 0.27911546 -0.62835105 -1.08244389]\n",
      " [-0.12543709  0.32797437  0.19539387]\n",
      " [ 0.19682716 -0.75412866 -0.2444272 ]\n",
      " [-0.75336768 -0.47433081 -0.70591534]\n",
      " [-1.78045062  0.07247648 -0.28442761]\n",
      " [-1.68680436  0.36305528 -0.8023842 ]\n",
      " [-0.04734259  0.63423766  0.25939664]\n",
      " [ 1.01252009 -1.36562301  0.53948185]\n",
      " [-0.76540397 -0.99493176 -0.46585343]\n",
      " [-0.40161728 -0.05100368 -1.06658058]\n",
      " [ 0.77999937  0.36598818 -1.44680586]\n",
      " [ 1.35251999  1.82239142  1.33502543]\n",
      " [-0.27332945 -1.19854689  1.20763828]\n",
      " [-0.49091686  1.13662171  0.34063983]\n",
      " [ 0.85388828  0.25469176  0.85119954]\n",
      " [-0.08773635  1.71035914  0.25727486]\n",
      " [ 0.29381952  1.8094198  -1.25368323]\n",
      " [-1.33621822  0.87894197 -1.07475035]\n",
      " [ 1.79633466 -0.52938616 -0.63860741]\n",
      " [ 1.7761802   1.39941471  2.04075348]\n",
      " [ 0.78508514 -0.98518512  2.0843054 ]\n",
      " [-0.35917312  0.70894626  1.09780067]\n",
      " [-0.24904688  0.51712149  1.07213909]\n",
      " [ 0.26890433 -1.22771938  0.43281673]\n",
      " [ 1.19476082 -0.81547706 -0.0260767 ]\n",
      " [-0.52208211  1.77491262  0.81607765]\n",
      " [ 0.29915313 -0.89220432  0.67975826]\n",
      " [-0.75519239 -0.07578384 -0.52425235]\n",
      " [ 0.56129983  0.47894681 -0.08618445]\n",
      " [ 0.28798867 -1.22126408 -1.4007128 ]\n",
      " [ 0.33027282  0.06152703  0.7778974 ]\n",
      " [ 2.22470597  0.8535687  -0.80804399]\n",
      " [ 0.99070366 -1.44818858 -0.34570286]\n",
      " [-0.16448002  1.63650394 -0.63584099]\n",
      " [-0.9034388  -0.20845141 -0.5525645 ]\n",
      " [ 1.00007921 -1.20789377 -1.04846431]\n",
      " [-0.52468094 -0.61534459  2.10425153]\n",
      " [ 0.82736068 -0.01904334 -1.1283497 ]\n",
      " [ 0.72496854 -1.12671861 -1.4555431 ]\n",
      " [ 1.0599153   0.21454643  1.07075808]\n",
      " [ 0.21267045  0.76431565 -0.53980538]\n",
      " [-1.10597037  0.58587232 -0.69593914]\n",
      " [-0.77002339 -0.5720668   0.14514913]\n",
      " [-0.44298177 -1.50831311 -0.53221592]\n",
      " [-2.26495745  0.52847768 -1.5142393 ]\n",
      " [-1.17433115 -0.05507715 -0.63052141]\n",
      " [ 1.40589288 -1.42471621  0.400862  ]\n",
      " [-0.13625602 -1.29766933  0.66339269]\n",
      " [-0.26516354  0.67771915  0.97100782]\n",
      " [ 2.01037701  1.25279257 -0.25102635]\n",
      " [-0.33127522  1.01158897  0.79862754]\n",
      " [ 0.52591916 -1.75474712  0.10231516]\n",
      " [-0.81727439  0.1768509   0.02667431]\n",
      " [ 0.78911448  0.21482708  0.93291684]\n",
      " [-0.55255433 -1.06992882 -0.29289984]\n",
      " [-0.11455849  0.27789413  2.44214318]\n",
      " [-0.13915488 -1.08163802 -0.22725541]\n",
      " [-0.54980284  0.38209674 -1.45147123]\n",
      " [-0.03631314  0.051174    0.36513414]\n",
      " [-0.68012998 -0.35047323 -1.33186262]\n",
      " [-0.57877255 -0.66099409  0.55352757]\n",
      " [-1.22481592  0.68729889  1.65849889]\n",
      " [-2.11543209  0.32586329  0.82080444]\n",
      " [-0.71923293 -0.5127398  -0.00891048]\n",
      " [-0.38820481 -0.42286561 -1.59000503]\n",
      " [ 1.02512287  0.99118117 -0.70613868]\n",
      " [-1.52718587  0.42240461 -0.4627164 ]\n",
      " [ 0.04038136 -0.43336985  0.83579517]\n",
      " [ 0.57915094 -0.84707449 -1.29016425]\n",
      " [-1.64074357  0.51335378 -1.09087341]\n",
      " [-0.59192657 -0.71542496  0.07337906]\n",
      " [-1.98511945  0.08403671  0.66402217]\n",
      " [-0.01179144 -0.4247731   0.22703674]\n",
      " [ 0.29095117 -2.93153469  2.13128092]\n",
      " [ 0.28222532 -0.77254617 -0.27333362]\n",
      " [ 0.38324384 -0.22642589 -1.95341324]\n",
      " [ 1.91413939 -0.22076079  1.17251576]\n",
      " [-0.77246003  1.45629939  0.42062956]\n",
      " [ 0.49542535 -1.17258094  1.36818757]\n",
      " [ 0.57434508  1.2174761  -0.51630292]\n",
      " [-0.5667917   2.23788681 -0.95885955]\n",
      " [-0.23047012  1.04950217  0.22736953]\n",
      " [ 0.47019212 -0.51495686  0.50640165]]\n",
      "\n",
      "Datos normalizados:\n",
      "[[0.86560599 0.62498652 0.7338962 ]\n",
      " [0.9691197  0.91404355 0.32743435]\n",
      " [0.68890884 0.51634604 0.5090646 ]\n",
      " [0.57179513 0.57453578 0.83271291]\n",
      " [0.64786928 0.5701295  0.62274875]\n",
      " [0.55509625 0.84047353 0.4878815 ]\n",
      " [0.55062292 0.37791657 0.        ]\n",
      " [0.62455049 0.71644286 0.37629102]\n",
      " [0.97538501 0.25967194 0.54002223]\n",
      " [0.44202716 0.84809691 0.83584764]\n",
      " [0.5162978  0.62065388 0.3460309 ]\n",
      " [0.05266562 0.47762752 0.56300303]\n",
      " [0.74973579 0.78301294 0.45002671]\n",
      " [0.41703689 0.33961126 0.23543257]\n",
      " [0.11226041 0.9304362  0.42460739]\n",
      " [0.38756329 0.29937842 0.69207677]\n",
      " [0.13231281 0.50425445 0.34443482]\n",
      " [0.56665114 0.44553992 0.28517715]\n",
      " [0.4765436  0.63053652 0.54433591]\n",
      " [0.54832275 0.42120884 0.45513563]\n",
      " [0.3366822  0.4753344  0.36154105]\n",
      " [0.10791607 0.58111167 0.44702313]\n",
      " [0.12877426 0.63732276 0.34197616]\n",
      " [0.49393789 0.6897817  0.55731634]\n",
      " [0.73000518 0.30291817 0.61412053]\n",
      " [0.33400131 0.37462663 0.41022809]\n",
      " [0.41502892 0.55722502 0.28839439]\n",
      " [0.67821494 0.63789011 0.21128076]\n",
      " [0.80573466 0.91962439 0.77546503]\n",
      " [0.44360296 0.33523825 0.74962959]\n",
      " [0.39513888 0.78696551 0.5737933 ]\n",
      " [0.69467251 0.61636035 0.67734011]\n",
      " [0.48494083 0.89795228 0.55688602]\n",
      " [0.56992623 0.9171151  0.25044803]\n",
      " [0.20686166 0.73711858 0.28673748]\n",
      " [0.90458721 0.46468421 0.37519179]\n",
      " [0.90009813 0.83780156 0.918594  ]\n",
      " [0.67934772 0.37651207 0.92742678]\n",
      " [0.42448267 0.70423372 0.72735338]\n",
      " [0.44901151 0.66712613 0.72214895]\n",
      " [0.56437678 0.32959497 0.59248773]\n",
      " [0.77059636 0.40934128 0.49941938]\n",
      " [0.38819733 0.91043985 0.67021703]\n",
      " [0.57111421 0.39449876 0.64257004]\n",
      " [0.33627578 0.55243142 0.39838419]\n",
      " [0.62950315 0.65974142 0.48722891]\n",
      " [0.56862751 0.33084372 0.22062891]\n",
      " [0.57804562 0.57899355 0.66247368]\n",
      " [1.         0.73221025 0.3408283 ]\n",
      " [0.72514592 0.28694625 0.43459588]\n",
      " [0.46784742 0.88366534 0.37575285]\n",
      " [0.30325629 0.52676751 0.39264219]\n",
      " [0.72723417 0.33343014 0.29206856]\n",
      " [0.38761848 0.44805596 0.93147207]\n",
      " [0.68876391 0.5634076  0.27586697]\n",
      " [0.66595771 0.34913309 0.20950875]\n",
      " [0.7405617  0.60859443 0.72186886]\n",
      " [0.55185159 0.71494467 0.39522987]\n",
      " [0.25814565 0.68042566 0.36356432]\n",
      " [0.33297241 0.45642784 0.53414576]\n",
      " [0.40581565 0.27531545 0.39676909]\n",
      " [0.         0.66932294 0.19760456]\n",
      " [0.24291939 0.55643703 0.37683172]\n",
      " [0.81762261 0.29148687 0.58600698]\n",
      " [0.47413386 0.31606348 0.63925093]\n",
      " [0.44542179 0.69819299 0.70163848]\n",
      " [0.95226169 0.80943821 0.45379726]\n",
      " [0.43069648 0.76277852 0.66667796]\n",
      " [0.62162268 0.22764396 0.52545858]\n",
      " [0.32244802 0.60130241 0.51011783]\n",
      " [0.68024519 0.60864872 0.69391323]\n",
      " [0.38141013 0.3601188  0.44530488]\n",
      " [0.47896663 0.62084874 1.        ]\n",
      " [0.47348818 0.35785371 0.45861825]\n",
      " [0.38202298 0.64100624 0.21033457]\n",
      " [0.49639452 0.57699081 0.578761  ]\n",
      " [0.35299472 0.49929406 0.23459244]\n",
      " [0.37557045 0.43922528 0.61696915]\n",
      " [0.23167472 0.70004614 0.8410688 ]\n",
      " [0.03330436 0.63012815 0.67117567]\n",
      " [0.34428517 0.46790437 0.50290087]\n",
      " [0.41801633 0.4852901  0.18223848]\n",
      " [0.73281224 0.75883072 0.36149575]\n",
      " [0.1643267  0.6488036  0.41086432]\n",
      " [0.51347698 0.48325811 0.67421595]\n",
      " [0.6334792  0.40322891 0.2430493 ]\n",
      " [0.13903356 0.66639729 0.28346755]\n",
      " [0.3726406  0.42869589 0.51959004]\n",
      " [0.0623294  0.58334794 0.6393786 ]\n",
      " [0.50185633 0.48492111 0.55075342]\n",
      " [0.56928736 0.         0.93695391]\n",
      " [0.56734381 0.41764606 0.44927311]\n",
      " [0.58984406 0.52329043 0.10853552]\n",
      " [0.93082631 0.52438632 0.74250638]\n",
      " [0.33242969 0.84880563 0.59001605]\n",
      " [0.61483068 0.34026124 0.78219065]\n",
      " [0.63240877 0.8026064  0.39999642]\n",
      " [0.37823899 1.         0.31024133]\n",
      " [0.45314919 0.77011264 0.55082091]\n",
      " [0.60921038 0.46747549 0.60741152]]\n",
      "\n",
      "Variables categóricas codificadas:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Generar datos aleatorios\n",
    "np.random.seed(0)\n",
    "data = np.random.randn(100, 3)  # 100 muestras con 3 características\n",
    "\n",
    "# Escalamiento de características\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Normalización\n",
    "normalizer = MinMaxScaler()\n",
    "data_normalized = normalizer.fit_transform(data)\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "categories = ['A', 'B', 'C', 'A', 'B', 'C']\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "categories_encoded = encoder.fit_transform(np.array(categories).reshape(-1, 1))\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Datos originales:\")\n",
    "print(data)\n",
    "print(\"\\nDatos escalados:\")\n",
    "print(data_scaled)\n",
    "print(\"\\nDatos normalizados:\")\n",
    "print(data_normalized)\n",
    "print(\"\\nVariables categóricas codificadas:\")\n",
    "print(categories_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se generan datos aleatorios de forma normal con np.random.randn. Luego, se aplican diferentes técnicas de preprocesamiento a los datos:\n",
    "\n",
    "* Escalamiento de características: se utiliza StandardScaler para estandarizar las características, es decir, hacer que tengan media cero y desviación estándar uno.\n",
    "\n",
    "* Normalización: se utiliza MinMaxScaler para normalizar los datos y que estén en el rango [0, 1].\n",
    "\n",
    "* Codificación de variables categóricas: se utiliza OneHotEncoder para codificar las variables categóricas en un formato de \"one-hot encoding\", convirtiéndolas en características binarias.\n",
    "\n",
    "Finalmente, se imprimen los datos originales, los datos escalados, los datos normalizados y las variables categóricas codificadas para observar los resultados. En un escenario real, es posible que debas aplicar múltiples transformaciones y tener en cuenta otras consideraciones específicas de tus datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en algún momento no sabes que parametros recibe cada función puedes directamente buscarlo con el siguiente comando, recuerda que las librerias están conformadas por clases, funciones definidas por todos los programadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Standardize features by removing the mean and scaling to unit variance.\n",
      "\n",
      "The standard score of a sample `x` is calculated as:\n",
      "\n",
      "    z = (x - u) / s\n",
      "\n",
      "where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      "and `s` is the standard deviation of the training samples or one if\n",
      "`with_std=False`.\n",
      "\n",
      "Centering and scaling happen independently on each feature by computing\n",
      "the relevant statistics on the samples in the training set. Mean and\n",
      "standard deviation are then stored to be used on later data using\n",
      ":meth:`transform`.\n",
      "\n",
      "Standardization of a dataset is a common requirement for many\n",
      "machine learning estimators: they might behave badly if the\n",
      "individual features do not more or less look like standard normally\n",
      "distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      "\n",
      "For instance many elements used in the objective function of\n",
      "a learning algorithm (such as the RBF kernel of Support Vector\n",
      "Machines or the L1 and L2 regularizers of linear models) assume that\n",
      "all features are centered around 0 and have variance in the same\n",
      "order. If a feature has a variance that is orders of magnitude larger\n",
      "than others, it might dominate the objective function and make the\n",
      "estimator unable to learn from other features correctly as expected.\n",
      "\n",
      "This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      "`with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      "\n",
      "Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "copy : bool, default=True\n",
      "    If False, try to avoid a copy and do inplace scaling instead.\n",
      "    This is not guaranteed to always work inplace; e.g. if the data is\n",
      "    not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      "    returned.\n",
      "\n",
      "with_mean : bool, default=True\n",
      "    If True, center the data before scaling.\n",
      "    This does not work (and will raise an exception) when attempted on\n",
      "    sparse matrices, because centering them entails building a dense\n",
      "    matrix which in common use cases is likely to be too large to fit in\n",
      "    memory.\n",
      "\n",
      "with_std : bool, default=True\n",
      "    If True, scale the data to unit variance (or equivalently,\n",
      "    unit standard deviation).\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "scale_ : ndarray of shape (n_features,) or None\n",
      "    Per feature relative scaling of the data to achieve zero mean and unit\n",
      "    variance. Generally this is calculated using `np.sqrt(var_)`. If a\n",
      "    variance is zero, we can't achieve unit variance, and the data is left\n",
      "    as-is, giving a scaling factor of 1. `scale_` is equal to `None`\n",
      "    when `with_std=False`.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       *scale_*\n",
      "\n",
      "mean_ : ndarray of shape (n_features,) or None\n",
      "    The mean value for each feature in the training set.\n",
      "    Equal to ``None`` when ``with_mean=False``.\n",
      "\n",
      "var_ : ndarray of shape (n_features,) or None\n",
      "    The variance for each feature in the training set. Used to compute\n",
      "    `scale_`. Equal to ``None`` when ``with_std=False``.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_samples_seen_ : int or ndarray of shape (n_features,)\n",
      "    The number of samples processed by the estimator for each feature.\n",
      "    If there are no missing samples, the ``n_samples_seen`` will be an\n",
      "    integer, otherwise it will be an array of dtype int. If\n",
      "    `sample_weights` are used it will be a float (if no missing data)\n",
      "    or an array of dtype float that sums the weights seen so far.\n",
      "    Will be reset on new calls to fit, but increments across\n",
      "    ``partial_fit`` calls.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "scale : Equivalent function without the estimator API.\n",
      "\n",
      ":class:`~sklearn.decomposition.PCA` : Further removes the linear\n",
      "    correlation across features with 'whiten=True'.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "transform.\n",
      "\n",
      "We use a biased estimator for the standard deviation, equivalent to\n",
      "`numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      "affect model performance.\n",
      "\n",
      "For a comparison of the different scalers, transformers, and normalizers,\n",
      "see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      "<sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.preprocessing import StandardScaler\n",
      ">>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      ">>> scaler = StandardScaler()\n",
      ">>> print(scaler.fit(data))\n",
      "StandardScaler()\n",
      ">>> print(scaler.mean_)\n",
      "[0.5 0.5]\n",
      ">>> print(scaler.transform(data))\n",
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n",
      ">>> print(scaler.transform([[2, 2]]))\n",
      "[[3. 3.]]\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\tesbh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "StandardScaler?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. El módulo sklearn.model_selection de scikit-learn \n",
    "\n",
    "Proporciona herramientas para dividir los datos en conjuntos de entrenamiento y prueba, realizar validación cruzada, buscar hiperparámetros óptimos y evaluar modelos. A continuación, se presentan algunas de las principales funcionalidades del módulo sklearn.model_selection:\n",
    "\n",
    "1. División de datos en conjuntos de entrenamiento y prueba:\n",
    "\n",
    "* train_test_split: Divide los datos en conjuntos de entrenamiento y prueba de forma aleatoria.\n",
    "2. Validación cruzada:\n",
    "\n",
    "* cross_val_score: Realiza validación cruzada utilizando un estimador y devuelve las puntuaciones de rendimiento.\n",
    "* KFold: Divide los datos en k pliegues (folds) para realizar validación cruzada.\n",
    "* StratifiedKFold: Divide los datos en k pliegues preservando la proporción de clases en cada pliegue.\n",
    "3. Búsqueda de hiperparámetros:\n",
    "\n",
    "* GridSearchCV: Realiza una búsqueda exhaustiva de hiperparámetros en una cuadrícula especificada.\n",
    "* RandomizedSearchCV: Realiza una búsqueda aleatoria de hiperparámetros en un espacio especificado.\n",
    "4. Métricas de evaluación:\n",
    "\n",
    "* accuracy_score: Calcula la precisión del clasificador en comparación con las etiquetas verdaderas.\n",
    "* precision_score, recall_score, f1_score: Calculan la precisión, el recall y la puntuación F1 de un clasificador.\n",
    "* confusion_matrix: Calcula la matriz de confusión para evaluar el rendimiento del clasificador.\n",
    "\n",
    "Estas son solo algunas de las funcionalidades principales que ofrece el módulo sklearn.model_selection. Puedes explorar la documentación oficial de scikit-learn para obtener información más detallada sobre cada función y cómo utilizarlas en tus tareas de evaluación y validación de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador: 0.55\n",
      "Puntuaciones de validación cruzada: [0.5 0.6 0.4 0.7 0.4]\n",
      "Precisión media de validación cruzada: 0.52\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generar datos aleatorios\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 3)  # 100 muestras con 3 características\n",
    "y = np.random.randint(0, 2, 100)  # Etiquetas binarias\n",
    "\n",
    "# División de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Crear un clasificador y ajustarlo al conjunto de entrenamiento\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calcular la precisión de las predicciones\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del clasificador:\", accuracy)\n",
    "\n",
    "# Realizar validación cruzada\n",
    "cv_scores = cross_val_score(classifier, X, y, cv=5)\n",
    "print(\"Puntuaciones de validación cruzada:\", cv_scores)\n",
    "print(\"Precisión media de validación cruzada:\", np.mean(cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se generan datos aleatorios de forma normal con np.random.randn y etiquetas binarias aleatorias con np.random.randint. Luego, se utilizan las siguientes funcionalidades de sklearn.model_selection:\n",
    "\n",
    "* División de datos en conjuntos de entrenamiento y prueba: train_test_split se utiliza para dividir los datos en un 80% para entrenamiento y un 20% para prueba.\n",
    "\n",
    "* Creación y ajuste del clasificador: se crea un clasificador de regresión logística (LogisticRegression) y se ajusta al conjunto de entrenamiento.\n",
    "\n",
    "* Realización de predicciones y cálculo de precisión: se realizan predicciones en el conjunto de prueba y se calcula la precisión de las predicciones utilizando accuracy_score.\n",
    "\n",
    "* Validación cruzada: cross_val_score se utiliza para realizar validación cruzada en el conjunto completo de datos (X, y) utilizando un clasificador y obtener las puntuaciones de rendimiento en cada fold. Luego, se calcula la precisión media de validación cruzada utilizando np.mean.\n",
    "\n",
    "En un escenario real, es posible que debas ajustar más parámetros, utilizar otras métricas de evaluación y explorar diferentes configuraciones de validación cruzada para obtener una evaluación más completa del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro random_state se utiliza en varias funciones de scikit-learn, incluyendo train_test_split, KFold, StratifiedKFold y muchas otras. Este parámetro controla la semilla utilizada por el generador de números aleatorios en esas funciones.\n",
    "\n",
    "Cuando se trabaja con algoritmos de machine learning que involucran aleatoriedad, como la división de datos en conjuntos de entrenamiento y prueba o la inicialización de parámetros aleatorios en modelos, es importante establecer una semilla o un valor de random_state para asegurarse de que los resultados sean reproducibles.\n",
    "\n",
    "Al fijar un valor específico para random_state, se garantiza que las operaciones que involucran aleatoriedad se realicen de la misma manera en diferentes ejecuciones del código. Esto es especialmente útil cuando se quiere obtener resultados consistentes y comparables entre diferentes experimentos o cuando se necesita depurar y entender el comportamiento de un algoritmo.\n",
    "\n",
    "Por ejemplo, si estableces random_state=0 en la función train_test_split, cada vez que ejecutes tu código con ese mismo valor de random_state, obtendrás exactamente la misma división de los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Es importante destacar que, para experimentos serios y en producción, es común utilizar semillas aleatorias diferentes o no establecer random_state en absoluto. Esto permite que los algoritmos se ejecuten en diferentes condiciones aleatorias y proporcionen una evaluación más robusta de su rendimiento en diferentes escenarios. Sin embargo, cuando se trata de reproducibilidad y depuración, establecer random_state puede ser de gran ayuda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Esta sólo es una pequeña parte de todo el poder de `scikit-learn` te invito a que revises su documentación en su pagina oficial ahi podras encontrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
